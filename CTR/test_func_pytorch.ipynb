{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn((9, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1670,  0.5806, -1.5908],\n",
      "        [ 0.2985, -0.3564,  1.0317],\n",
      "        [ 0.0365,  0.3392, -0.8458],\n",
      "        [ 1.3202, -2.5964,  0.6469],\n",
      "        [-0.4819,  0.9627, -0.1110],\n",
      "        [ 0.3606,  0.4198,  2.1696],\n",
      "        [ 0.5945, -0.5221, -1.0432],\n",
      "        [-0.0383, -0.0352, -0.8681],\n",
      "        [ 1.3339, -0.7215, -0.7266]])\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.1670, -0.4194, -2.5908],\n",
       "        [-0.7015, -1.3564,  0.0317],\n",
       "        [-0.9635, -0.6608, -1.8458],\n",
       "        [ 0.3202, -3.5964, -0.3531],\n",
       "        [-1.4819, -0.0373, -1.1110],\n",
       "        [-0.6394, -0.5802,  1.1696],\n",
       "        [-0.4055, -1.5221, -2.0432],\n",
       "        [-1.0383, -1.0352, -1.8681],\n",
       "        [ 0.3339, -1.7215, -1.7266]], device='cuda:0')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.cuda()-1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2,  0, -2],\n",
       "        [ 0, -1,  0],\n",
       "        [ 0,  0, -1],\n",
       "        [ 0, -3,  0],\n",
       "        [-1,  0, -1],\n",
       "        [ 0,  0,  1],\n",
       "        [ 0, -1, -2],\n",
       "        [-1, -1, -1],\n",
       "        [ 0, -1, -1]], device='cuda:0')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a.cuda()-1.0).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1428,  1.9910,  1.0452],\n",
      "        [ 0.5195,  1.2930, -2.0958],\n",
      "        [ 0.2188,  0.5346,  0.7148]])\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "b = torch.randn((3, 3))\n",
    "print(b)\n",
    "print(b.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1428,  1.9910,  1.0452],\n",
       "        [ 0.5195,  1.2930, -2.0958],\n",
       "        [ 0.2188,  0.5346,  0.7148]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.9085,  0.1791,  0.1699],\n",
       "         [ 1.1165, -0.3787, -0.4030],\n",
       "         [ 0.3072,  0.3901,  0.4899]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=torch.repeat_interleave(b.cuda(), repeats=torch.tensor([2, 4, 3]).cuda(), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1428,  1.9910,  1.0452],\n",
      "        [-0.1428,  1.9910,  1.0452],\n",
      "        [ 0.5195,  1.2930, -2.0958],\n",
      "        [ 0.5195,  1.2930, -2.0958],\n",
      "        [ 0.5195,  1.2930, -2.0958],\n",
      "        [ 0.5195,  1.2930, -2.0958],\n",
      "        [ 0.2188,  0.5346,  0.7148],\n",
      "        [ 0.2188,  0.5346,  0.7148],\n",
      "        [ 0.2188,  0.5346,  0.7148]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.0011, -0.0325,  0.5785],\n",
      "        [ 0.3196, -0.5192, -1.7581],\n",
      "        [-0.7026, -0.2435,  0.6680],\n",
      "        [ 1.3151, -1.2109, -2.1068],\n",
      "        [ 0.3079,  0.3630,  0.0927],\n",
      "        [ 0.3705, -0.2366,  1.0386],\n",
      "        [ 0.7515, -1.4720,  1.1032],\n",
      "        [ 0.0110,  0.2586, -0.6078],\n",
      "        [-0.7980, -0.8207,  0.1848]])\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "chunk_size_list = torch.tensor([2, 4, 3])\n",
    "print(chunk_size_list)\n",
    "chunk_size_list = [2, 4, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_list = torch.split(a, split_size_or_sections=chunk_size_list, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3766,  0.6445,  0.3259],\n",
       "         [-1.3413,  0.9711,  0.7166],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.8157, -0.8397,  1.2337],\n",
       "         [ 0.4120, -0.5992, -1.0866],\n",
       "         [-0.8140,  0.7608,  0.0100],\n",
       "         [-0.1946,  0.2819,  1.7048]],\n",
       "\n",
       "        [[-0.2292, -0.5125,  1.4070],\n",
       "         [ 0.5587,  0.3426, -0.8609],\n",
       "         [-1.7520,  0.3980, -0.4850],\n",
       "         [ 0.0000,  0.0000,  0.0000]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.utils.rnn.pad_sequence(chunk_list, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.3766,  0.6445,  0.3259],\n",
       "         [-1.3413,  0.9711,  0.7166]]), tensor([[ 0.8157, -0.8397,  1.2337],\n",
       "         [ 0.4120, -0.5992, -1.0866],\n",
       "         [-0.8140,  0.7608,  0.0100],\n",
       "         [-0.1946,  0.2819,  1.7048]]), tensor([[-0.2292, -0.5125,  1.4070],\n",
       "         [ 0.5587,  0.3426, -0.8609],\n",
       "         [-1.7520,  0.3980, -0.4850]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torchvision.models import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "epoch 1\n",
      "learning rate:0.000997\n",
      "epoch 2\n",
      "learning rate:0.000994\n",
      "epoch 3\n",
      "learning rate:0.000991\n",
      "epoch 4\n",
      "learning rate:0.000988\n",
      "epoch 5\n",
      "learning rate:0.000985\n",
      "epoch 6\n",
      "learning rate:0.000982\n",
      "epoch 7\n",
      "learning rate:0.000979\n",
      "epoch 8\n",
      "learning rate:0.000976\n",
      "epoch 9\n",
      "learning rate:0.000973\n",
      "epoch 10\n",
      "learning rate:0.000970\n",
      "epoch 11\n",
      "learning rate:0.000967\n",
      "epoch 12\n",
      "learning rate:0.000964\n",
      "epoch 13\n",
      "learning rate:0.000961\n",
      "epoch 14\n",
      "learning rate:0.000958\n",
      "epoch 15\n",
      "learning rate:0.000955\n",
      "epoch 16\n",
      "learning rate:0.000952\n",
      "epoch 17\n",
      "learning rate:0.000949\n",
      "epoch 18\n",
      "learning rate:0.000946\n",
      "epoch 19\n",
      "learning rate:0.000943\n",
      "epoch 20\n",
      "learning rate:0.000940\n",
      "epoch 21\n",
      "learning rate:0.000937\n",
      "epoch 22\n",
      "learning rate:0.000934\n",
      "epoch 23\n",
      "learning rate:0.000931\n",
      "epoch 24\n",
      "learning rate:0.000928\n",
      "epoch 25\n",
      "learning rate:0.000925\n",
      "epoch 26\n",
      "learning rate:0.000922\n",
      "epoch 27\n",
      "learning rate:0.000919\n",
      "epoch 28\n",
      "learning rate:0.000916\n",
      "epoch 29\n",
      "learning rate:0.000913\n",
      "epoch 30\n",
      "learning rate:0.000910\n",
      "epoch 31\n",
      "learning rate:0.000907\n",
      "epoch 32\n",
      "learning rate:0.000903\n",
      "epoch 33\n",
      "learning rate:0.000900\n",
      "epoch 34\n",
      "learning rate:0.000897\n",
      "epoch 35\n",
      "learning rate:0.000894\n",
      "epoch 36\n",
      "learning rate:0.000891\n",
      "epoch 37\n",
      "learning rate:0.000888\n",
      "epoch 38\n",
      "learning rate:0.000885\n",
      "epoch 39\n",
      "learning rate:0.000882\n",
      "epoch 40\n",
      "learning rate:0.000879\n",
      "epoch 41\n",
      "learning rate:0.000876\n",
      "epoch 42\n",
      "learning rate:0.000873\n",
      "epoch 43\n",
      "learning rate:0.000870\n",
      "epoch 44\n",
      "learning rate:0.000867\n",
      "epoch 45\n",
      "learning rate:0.000864\n",
      "epoch 46\n",
      "learning rate:0.000861\n",
      "epoch 47\n",
      "learning rate:0.000858\n",
      "epoch 48\n",
      "learning rate:0.000855\n",
      "epoch 49\n",
      "learning rate:0.000852\n",
      "epoch 50\n",
      "learning rate:0.000849\n",
      "epoch 51\n",
      "learning rate:0.000846\n",
      "epoch 52\n",
      "learning rate:0.000843\n",
      "epoch 53\n",
      "learning rate:0.000839\n",
      "epoch 54\n",
      "learning rate:0.000836\n",
      "epoch 55\n",
      "learning rate:0.000833\n",
      "epoch 56\n",
      "learning rate:0.000830\n",
      "epoch 57\n",
      "learning rate:0.000827\n",
      "epoch 58\n",
      "learning rate:0.000824\n",
      "epoch 59\n",
      "learning rate:0.000821\n",
      "epoch 60\n",
      "learning rate:0.000818\n",
      "epoch 61\n",
      "learning rate:0.000815\n",
      "epoch 62\n",
      "learning rate:0.000812\n",
      "epoch 63\n",
      "learning rate:0.000809\n",
      "epoch 64\n",
      "learning rate:0.000806\n",
      "epoch 65\n",
      "learning rate:0.000803\n",
      "epoch 66\n",
      "learning rate:0.000800\n",
      "epoch 67\n",
      "learning rate:0.000797\n",
      "epoch 68\n",
      "learning rate:0.000793\n",
      "epoch 69\n",
      "learning rate:0.000790\n",
      "epoch 70\n",
      "learning rate:0.000787\n",
      "epoch 71\n",
      "learning rate:0.000784\n",
      "epoch 72\n",
      "learning rate:0.000781\n",
      "epoch 73\n",
      "learning rate:0.000778\n",
      "epoch 74\n",
      "learning rate:0.000775\n",
      "epoch 75\n",
      "learning rate:0.000772\n",
      "epoch 76\n",
      "learning rate:0.000769\n",
      "epoch 77\n",
      "learning rate:0.000766\n",
      "epoch 78\n",
      "learning rate:0.000763\n",
      "epoch 79\n",
      "learning rate:0.000760\n",
      "epoch 80\n",
      "learning rate:0.000756\n",
      "epoch 81\n",
      "learning rate:0.000753\n",
      "epoch 82\n",
      "learning rate:0.000750\n",
      "epoch 83\n",
      "learning rate:0.000747\n",
      "epoch 84\n",
      "learning rate:0.000744\n",
      "epoch 85\n",
      "learning rate:0.000741\n",
      "epoch 86\n",
      "learning rate:0.000738\n",
      "epoch 87\n",
      "learning rate:0.000735\n",
      "epoch 88\n",
      "learning rate:0.000732\n",
      "epoch 89\n",
      "learning rate:0.000729\n",
      "epoch 90\n",
      "learning rate:0.000725\n",
      "epoch 91\n",
      "learning rate:0.000722\n",
      "epoch 92\n",
      "learning rate:0.000719\n",
      "epoch 93\n",
      "learning rate:0.000716\n",
      "epoch 94\n",
      "learning rate:0.000713\n",
      "epoch 95\n",
      "learning rate:0.000710\n",
      "epoch 96\n",
      "learning rate:0.000707\n",
      "epoch 97\n",
      "learning rate:0.000704\n",
      "epoch 98\n",
      "learning rate:0.000700\n",
      "epoch 99\n",
      "learning rate:0.000697\n",
      "epoch 100\n",
      "learning rate:0.000694\n",
      "epoch 101\n",
      "learning rate:0.000691\n",
      "epoch 102\n",
      "learning rate:0.000688\n",
      "epoch 103\n",
      "learning rate:0.000685\n",
      "epoch 104\n",
      "learning rate:0.000682\n",
      "epoch 105\n",
      "learning rate:0.000679\n",
      "epoch 106\n",
      "learning rate:0.000675\n",
      "epoch 107\n",
      "learning rate:0.000672\n",
      "epoch 108\n",
      "learning rate:0.000669\n",
      "epoch 109\n",
      "learning rate:0.000666\n",
      "epoch 110\n",
      "learning rate:0.000663\n",
      "epoch 111\n",
      "learning rate:0.000660\n",
      "epoch 112\n",
      "learning rate:0.000657\n",
      "epoch 113\n",
      "learning rate:0.000654\n",
      "epoch 114\n",
      "learning rate:0.000650\n",
      "epoch 115\n",
      "learning rate:0.000647\n",
      "epoch 116\n",
      "learning rate:0.000644\n",
      "epoch 117\n",
      "learning rate:0.000641\n",
      "epoch 118\n",
      "learning rate:0.000638\n",
      "epoch 119\n",
      "learning rate:0.000635\n",
      "epoch 120\n",
      "learning rate:0.000631\n",
      "epoch 121\n",
      "learning rate:0.000628\n",
      "epoch 122\n",
      "learning rate:0.000625\n",
      "epoch 123\n",
      "learning rate:0.000622\n",
      "epoch 124\n",
      "learning rate:0.000619\n",
      "epoch 125\n",
      "learning rate:0.000616\n",
      "epoch 126\n",
      "learning rate:0.000612\n",
      "epoch 127\n",
      "learning rate:0.000609\n",
      "epoch 128\n",
      "learning rate:0.000606\n",
      "epoch 129\n",
      "learning rate:0.000603\n",
      "epoch 130\n",
      "learning rate:0.000600\n",
      "epoch 131\n",
      "learning rate:0.000597\n",
      "epoch 132\n",
      "learning rate:0.000593\n",
      "epoch 133\n",
      "learning rate:0.000590\n",
      "epoch 134\n",
      "learning rate:0.000587\n",
      "epoch 135\n",
      "learning rate:0.000584\n",
      "epoch 136\n",
      "learning rate:0.000581\n",
      "epoch 137\n",
      "learning rate:0.000578\n",
      "epoch 138\n",
      "learning rate:0.000574\n",
      "epoch 139\n",
      "learning rate:0.000571\n",
      "epoch 140\n",
      "learning rate:0.000568\n",
      "epoch 141\n",
      "learning rate:0.000565\n",
      "epoch 142\n",
      "learning rate:0.000562\n",
      "epoch 143\n",
      "learning rate:0.000558\n",
      "epoch 144\n",
      "learning rate:0.000555\n",
      "epoch 145\n",
      "learning rate:0.000552\n",
      "epoch 146\n",
      "learning rate:0.000549\n",
      "epoch 147\n",
      "learning rate:0.000546\n",
      "epoch 148\n",
      "learning rate:0.000542\n",
      "epoch 149\n",
      "learning rate:0.000539\n",
      "epoch 150\n",
      "learning rate:0.000536\n",
      "epoch 151\n",
      "learning rate:0.000533\n",
      "epoch 152\n",
      "learning rate:0.000529\n",
      "epoch 153\n",
      "learning rate:0.000526\n",
      "epoch 154\n",
      "learning rate:0.000523\n",
      "epoch 155\n",
      "learning rate:0.000520\n",
      "epoch 156\n",
      "learning rate:0.000517\n",
      "epoch 157\n",
      "learning rate:0.000513\n",
      "epoch 158\n",
      "learning rate:0.000510\n",
      "epoch 159\n",
      "learning rate:0.000507\n",
      "epoch 160\n",
      "learning rate:0.000504\n",
      "epoch 161\n",
      "learning rate:0.000500\n",
      "epoch 162\n",
      "learning rate:0.000497\n",
      "epoch 163\n",
      "learning rate:0.000494\n",
      "epoch 164\n",
      "learning rate:0.000491\n",
      "epoch 165\n",
      "learning rate:0.000487\n",
      "epoch 166\n",
      "learning rate:0.000484\n",
      "epoch 167\n",
      "learning rate:0.000481\n",
      "epoch 168\n",
      "learning rate:0.000478\n",
      "epoch 169\n",
      "learning rate:0.000474\n",
      "epoch 170\n",
      "learning rate:0.000471\n",
      "epoch 171\n",
      "learning rate:0.000468\n",
      "epoch 172\n",
      "learning rate:0.000465\n",
      "epoch 173\n",
      "learning rate:0.000461\n",
      "epoch 174\n",
      "learning rate:0.000458\n",
      "epoch 175\n",
      "learning rate:0.000455\n",
      "epoch 176\n",
      "learning rate:0.000452\n",
      "epoch 177\n",
      "learning rate:0.000448\n",
      "epoch 178\n",
      "learning rate:0.000445\n",
      "epoch 179\n",
      "learning rate:0.000442\n",
      "epoch 180\n",
      "learning rate:0.000438\n",
      "epoch 181\n",
      "learning rate:0.000435\n",
      "epoch 182\n",
      "learning rate:0.000432\n",
      "epoch 183\n",
      "learning rate:0.000429\n",
      "epoch 184\n",
      "learning rate:0.000425\n",
      "epoch 185\n",
      "learning rate:0.000422\n",
      "epoch 186\n",
      "learning rate:0.000419\n",
      "epoch 187\n",
      "learning rate:0.000415\n",
      "epoch 188\n",
      "learning rate:0.000412\n",
      "epoch 189\n",
      "learning rate:0.000409\n",
      "epoch 190\n",
      "learning rate:0.000405\n",
      "epoch 191\n",
      "learning rate:0.000402\n",
      "epoch 192\n",
      "learning rate:0.000399\n",
      "epoch 193\n",
      "learning rate:0.000395\n",
      "epoch 194\n",
      "learning rate:0.000392\n",
      "epoch 195\n",
      "learning rate:0.000389\n",
      "epoch 196\n",
      "learning rate:0.000385\n",
      "epoch 197\n",
      "learning rate:0.000382\n",
      "epoch 198\n",
      "learning rate:0.000379\n",
      "epoch 199\n",
      "learning rate:0.000375\n",
      "epoch 200\n",
      "learning rate:0.000372\n",
      "epoch 201\n",
      "learning rate:0.000369\n",
      "epoch 202\n",
      "learning rate:0.000365\n",
      "epoch 203\n",
      "learning rate:0.000362\n",
      "epoch 204\n",
      "learning rate:0.000359\n",
      "epoch 205\n",
      "learning rate:0.000355\n",
      "epoch 206\n",
      "learning rate:0.000352\n",
      "epoch 207\n",
      "learning rate:0.000349\n",
      "epoch 208\n",
      "learning rate:0.000345\n",
      "epoch 209\n",
      "learning rate:0.000342\n",
      "epoch 210\n",
      "learning rate:0.000338\n",
      "epoch 211\n",
      "learning rate:0.000335\n",
      "epoch 212\n",
      "learning rate:0.000332\n",
      "epoch 213\n",
      "learning rate:0.000328\n",
      "epoch 214\n",
      "learning rate:0.000325\n",
      "epoch 215\n",
      "learning rate:0.000321\n",
      "epoch 216\n",
      "learning rate:0.000318\n",
      "epoch 217\n",
      "learning rate:0.000315\n",
      "epoch 218\n",
      "learning rate:0.000311\n",
      "epoch 219\n",
      "learning rate:0.000308\n",
      "epoch 220\n",
      "learning rate:0.000304\n",
      "epoch 221\n",
      "learning rate:0.000301\n",
      "epoch 222\n",
      "learning rate:0.000297\n",
      "epoch 223\n",
      "learning rate:0.000294\n",
      "epoch 224\n",
      "learning rate:0.000291\n",
      "epoch 225\n",
      "learning rate:0.000287\n",
      "epoch 226\n",
      "learning rate:0.000284\n",
      "epoch 227\n",
      "learning rate:0.000280\n",
      "epoch 228\n",
      "learning rate:0.000277\n",
      "epoch 229\n",
      "learning rate:0.000273\n",
      "epoch 230\n",
      "learning rate:0.000270\n",
      "epoch 231\n",
      "learning rate:0.000266\n",
      "epoch 232\n",
      "learning rate:0.000263\n",
      "epoch 233\n",
      "learning rate:0.000259\n",
      "epoch 234\n",
      "learning rate:0.000256\n",
      "epoch 235\n",
      "learning rate:0.000252\n",
      "epoch 236\n",
      "learning rate:0.000249\n",
      "epoch 237\n",
      "learning rate:0.000245\n",
      "epoch 238\n",
      "learning rate:0.000242\n",
      "epoch 239\n",
      "learning rate:0.000238\n",
      "epoch 240\n",
      "learning rate:0.000235\n",
      "epoch 241\n",
      "learning rate:0.000231\n",
      "epoch 242\n",
      "learning rate:0.000228\n",
      "epoch 243\n",
      "learning rate:0.000224\n",
      "epoch 244\n",
      "learning rate:0.000221\n",
      "epoch 245\n",
      "learning rate:0.000217\n",
      "epoch 246\n",
      "learning rate:0.000214\n",
      "epoch 247\n",
      "learning rate:0.000210\n",
      "epoch 248\n",
      "learning rate:0.000207\n",
      "epoch 249\n",
      "learning rate:0.000203\n",
      "epoch 250\n",
      "learning rate:0.000199\n",
      "epoch 251\n",
      "learning rate:0.000196\n",
      "epoch 252\n",
      "learning rate:0.000192\n",
      "epoch 253\n",
      "learning rate:0.000189\n",
      "epoch 254\n",
      "learning rate:0.000185\n",
      "epoch 255\n",
      "learning rate:0.000181\n",
      "epoch 256\n",
      "learning rate:0.000178\n",
      "epoch 257\n",
      "learning rate:0.000174\n",
      "epoch 258\n",
      "learning rate:0.000170\n",
      "epoch 259\n",
      "learning rate:0.000167\n",
      "epoch 260\n",
      "learning rate:0.000163\n",
      "epoch 261\n",
      "learning rate:0.000159\n",
      "epoch 262\n",
      "learning rate:0.000156\n",
      "epoch 263\n",
      "learning rate:0.000152\n",
      "epoch 264\n",
      "learning rate:0.000148\n",
      "epoch 265\n",
      "learning rate:0.000145\n",
      "epoch 266\n",
      "learning rate:0.000141\n",
      "epoch 267\n",
      "learning rate:0.000137\n",
      "epoch 268\n",
      "learning rate:0.000133\n",
      "epoch 269\n",
      "learning rate:0.000130\n",
      "epoch 270\n",
      "learning rate:0.000126\n",
      "epoch 271\n",
      "learning rate:0.000122\n",
      "epoch 272\n",
      "learning rate:0.000118\n",
      "epoch 273\n",
      "learning rate:0.000115\n",
      "epoch 274\n",
      "learning rate:0.000111\n",
      "epoch 275\n",
      "learning rate:0.000107\n",
      "epoch 276\n",
      "learning rate:0.000103\n",
      "epoch 277\n",
      "learning rate:0.000099\n",
      "epoch 278\n",
      "learning rate:0.000095\n",
      "epoch 279\n",
      "learning rate:0.000091\n",
      "epoch 280\n",
      "learning rate:0.000087\n",
      "epoch 281\n",
      "learning rate:0.000083\n",
      "epoch 282\n",
      "learning rate:0.000079\n",
      "epoch 283\n",
      "learning rate:0.000076\n",
      "epoch 284\n",
      "learning rate:0.000071\n",
      "epoch 285\n",
      "learning rate:0.000067\n",
      "epoch 286\n",
      "learning rate:0.000063\n",
      "epoch 287\n",
      "learning rate:0.000059\n",
      "epoch 288\n",
      "learning rate:0.000055\n",
      "epoch 289\n",
      "learning rate:0.000051\n",
      "epoch 290\n",
      "learning rate:0.000047\n",
      "epoch 291\n",
      "learning rate:0.000043\n",
      "epoch 292\n",
      "learning rate:0.000038\n",
      "epoch 293\n",
      "learning rate:0.000034\n",
      "epoch 294\n",
      "learning rate:0.000030\n",
      "epoch 295\n",
      "learning rate:0.000025\n",
      "epoch 296\n",
      "learning rate:0.000021\n",
      "epoch 297\n",
      "learning rate:0.000016\n",
      "epoch 298\n",
      "learning rate:0.000011\n",
      "epoch 299\n",
      "learning rate:0.000006\n",
      "epoch 300\n",
      "learning rate:0.000000\n"
     ]
    }
   ],
   "source": [
    "def poly_scheduler(epoch, num_epochs=300, power=0.9):\n",
    "    print(\"epoch\", epoch)\n",
    "    return (1-epoch/num_epochs)**power\n",
    "\n",
    "model = resnet18()\n",
    "optimizer = SGD(model.parameters(), lr=0.001)\n",
    "lr_scheduler = LambdaLR(optimizer=optimizer, lr_lambda=poly_scheduler)\n",
    "\n",
    "for epoch in range(300):\n",
    "    lr_scheduler.step()\n",
    "    print(\"learning rate:{:.6f}\".format(optimizer.param_groups[0]['lr']))\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn((2, 4, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3376,  0.5404,  1.4118],\n",
       "         [ 0.9021,  0.7833,  0.3959],\n",
       "         [-0.7176,  0.0132, -0.5202],\n",
       "         [ 0.4959,  0.4361, -1.0407]],\n",
       "\n",
       "        [[-0.6083, -0.9036, -1.8689],\n",
       "         [-0.4350, -0.3950, -0.0119],\n",
       "         [-0.4589, -0.0028,  0.4012],\n",
       "         [-1.0823, -0.1478, -0.9523]]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.arange(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3376,  0.5404,  1.4118],\n",
       "        [-0.4350, -0.3950, -0.0119]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[x, y, :].squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1]), tensor([0, 1]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
