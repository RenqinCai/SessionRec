{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import argparse\n",
    "import torch\n",
    "# import lib\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from dataset import *\n",
    "from loss import *\n",
    "from model import *\n",
    "from optimizer import *\n",
    "from trainer import *\n",
    "from torch.utils import data\n",
    "import pickle\n",
    "import sys\n",
    "from dataset_time_cut import *\n",
    "from logger import *\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../PyTorch_GBW_LM')\n",
    "sys.path.insert(0, '../PyTorch_GBW_LM/log_uniform')\n",
    "\n",
    "from sparse_model import RNNModel, SampledSoftmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--hidden_size', default=50, type=int)\n",
    "parser.add_argument('--num_layers', default=1, type=int)\n",
    "parser.add_argument('--batch_size', default=100, type=int)\n",
    "parser.add_argument('--dropout_input', default=0, type=float)\n",
    "parser.add_argument('--dropout_hidden', default=.2, type=float)\n",
    "\n",
    "# parse the optimizer arguments\n",
    "parser.add_argument('--optimizer_type', default='Adagrad', type=str)\n",
    "parser.add_argument('--final_act', default='tanh', type=str)\n",
    "parser.add_argument('--lr', default=.05, type=float)\n",
    "parser.add_argument('--weight_decay', default=0.0, type=float)\n",
    "parser.add_argument('--momentum', default=0.1, type=float)\n",
    "parser.add_argument('--eps', default=1e-6, type=float)\n",
    "\n",
    "parser.add_argument(\"-seed\", type=int, default=7,\n",
    "\t\t\t\t\t help=\"Seed for random initialization\")\n",
    "parser.add_argument(\"-sigma\", type=float, default=None,\n",
    "\t\t\t\t\t help=\"init weight -1: range [-sigma, sigma], -2: range [0, sigma]\")\n",
    "parser.add_argument(\"--embedding_dim\", type=int, default=-1,\n",
    "\t\t\t\t\t help=\"using embedding\")\n",
    "# parse the loss type\n",
    "parser.add_argument('--loss_type', default='TOP1', type=str)\n",
    "# parser.add_argument('--loss_type', default='BPR', type=str)\n",
    "parser.add_argument('--topk', default=5, type=int)\n",
    "# etc\n",
    "parser.add_argument('--bptt', default=1, type=int)\n",
    "parser.add_argument('--test_observed', default=5, type=int)\n",
    "parser.add_argument('--window_size', default=30, type=int)\n",
    "parser.add_argument('--warm_start', default=5, type=int)\n",
    "\n",
    "parser.add_argument('--n_epochs', default=20, type=int)\n",
    "parser.add_argument('--time_sort', default=False, type=bool)\n",
    "parser.add_argument('--model_name', default='GRU4REC', type=str)\n",
    "parser.add_argument('--save_dir', default='models', type=str)\n",
    "parser.add_argument('--data_folder', default='../Data/movielen/1m/', type=str)\n",
    "parser.add_argument('--data_action', default='item.pickle', type=str)\n",
    "parser.add_argument('--data_cate', default='cate.pickle', type=str)\n",
    "parser.add_argument('--data_time', default='time.pickle', type=str)\n",
    "parser.add_argument(\"--is_eval\", action='store_true')\n",
    "parser.add_argument('--load_model', default=None,  type=str)\n",
    "parser.add_argument('--checkpoint_dir', type=str, default='checkpoint')\n",
    "parser.add_argument('--data_name', default=None, type=str)\n",
    "parser.add_argument('--shared_embedding', default=None, type=int)\n",
    "parser.add_argument('--patience', default=1000)\n",
    "parser.add_argument('--negative_num', default=1000, type=int)\n",
    "\n",
    "# Get the arguments\n",
    "args = parser.parse_args(args=[])\n",
    "args.cuda = torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.data_folder = \"../Data/tmall/100k_unknown_cate/\"\n",
    "args.data_action = \"item_time.pickle\"\n",
    "args.data_cate = \"cate_time.pickle\"\n",
    "args.data_time = \"time_time.pickle\"\n",
    "args.data_name = \"taobao\"\n",
    "args.valid_start_time = 1512172800\n",
    "valid_start_time = args.valid_start_time\n",
    "args.test_start_time = 1512259200\n",
    "test_start_time = args.test_start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.embedding_dim = 300\n",
    "args.hidden_size = 300\n",
    "args.lr = 0.0001\n",
    "args.window_size = 5\n",
    "args.test_observed = 5\n",
    "args.n_epochs = 300\n",
    "args.shared_embedding = 1\n",
    "args.batch_size = 300\n",
    "args.optimizer_type = \"Adam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_file = \"data.pickle\"\n",
    "# f = open(data_file, \"rb\")\n",
    "# data_map = pickle.load(f)\n",
    "# data_obj = data_map[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action seq num 51275\n",
      "cate seq num 51275\n",
      "time seq num 51275\n",
      "loading item map\n",
      "finish loading item map\n",
      "observed_threshold 5 5\n",
      "loading data\n",
      "valid_start_time 1512172800\n",
      "test start time 1512259200\n",
      "subseq num for training 2738883\n",
      "subseq len num for training 2738883\n",
      "seq idx num for training 2738883\n",
      "subseq num for testing 430797\n",
      "subseq len num for testing 430797\n",
      "++++++++++\n",
      "valid load\n",
      "item num 68008\n"
     ]
    }
   ],
   "source": [
    "hidden_size = args.hidden_size\n",
    "num_layers = args.num_layers\n",
    "batch_size = args.batch_size\n",
    "dropout_input = args.dropout_input\n",
    "dropout_hidden = args.dropout_hidden\n",
    "embedding_dim = args.embedding_dim\n",
    "final_act = args.final_act\n",
    "loss_type = args.loss_type\n",
    "topk = args.topk\n",
    "optimizer_type = args.optimizer_type\n",
    "lr = args.lr\n",
    "weight_decay = args.weight_decay\n",
    "momentum = args.momentum\n",
    "eps = args.eps\n",
    "BPTT = args.bptt\n",
    "\n",
    "n_epochs = args.n_epochs\n",
    "time_sort = args.time_sort\n",
    "\n",
    "window_size = args.window_size\n",
    "shared_embedding = args.shared_embedding\n",
    "\n",
    "if embedding_dim == -1:\n",
    "    print(\"embedding dim not -1\", embedding_dim)\n",
    "    raise AssertionError()\n",
    "\n",
    "observed_threshold = args.test_observed\n",
    "\n",
    "data_action = args.data_folder+args.data_action\n",
    "data_cate = args.data_folder+args.data_cate\n",
    "data_time = args.data_folder+args.data_time\n",
    "\n",
    "data_obj = Data(data_action, data_cate, data_time, valid_start_time, test_start_time, observed_threshold, window_size)\n",
    "\n",
    "train_data = data_obj.train_dataset\n",
    "\n",
    "print(\"+\"*10)\n",
    "print(\"valid load\")\n",
    "\n",
    "valid_data = data_obj.test_dataset\n",
    "test_data = data_obj.test_dataset\n",
    "\n",
    "input_size = len(data_obj.items)\n",
    "output_size = input_size\n",
    "\n",
    "negative_num = args.negative_num\n",
    "# print(\"input_size\", input_size)\n",
    "\n",
    "train_data_loader = dataset.DataLoader(train_data, batch_size)\n",
    "\n",
    "valid_data_loader = dataset.DataLoader(valid_data, batch_size)\n",
    "\n",
    "data_name = args.data_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68008"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = self.m_folder+\"/\"+str(index)+\".pickle\"\n",
    "print(\"file name\", file_name)\n",
    "f_step = open(file_name, \"rb\")\n",
    "\n",
    "step_data_map = pickle.load(f_step)\n",
    "f_step.close()\n",
    "\n",
    "x_long_cate_action_list_step = step_data_map[\"long_action_cate\"]\n",
    "x_long_cateNum_list_step = step_data_map[\"long_cateNum\"]\n",
    "\n",
    "x_long_cate_actionNum_list_step = step_data_map[\"long_actionNum_cate\"]\n",
    "x_long_cate_list_step = step_data_map[\"long_cate\"]\n",
    "x_short_action_list_step = step_data_map[\"short_action\"]\n",
    "x_short_cate_list_step = step_data_map[\"short_cate\"]\n",
    "x_short_actionNum_list_step = step_data_map[\"short_actionNum\"]\n",
    "y_action_step = step_data_map[\"target_action\"]\n",
    "y_cate_step = step_data_map[\"target_cate\"]\n",
    "y_action_idx_step = step_data_map[\"target_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_file hcdmg2_01_57_19_07_300_300_300_Adam_0.0001_5_1_taobao\n",
      "share embedding\n"
     ]
    }
   ],
   "source": [
    "ss = SampledSoftmax(output_size, negative_num, embedding_dim, None)\n",
    "\n",
    "log = Logger()\n",
    "log.addIOWriter(args)\n",
    "\n",
    "model = GRU4REC(log, ss, window_size, input_size, hidden_size, output_size,\n",
    "                    final_act=final_act,\n",
    "                    num_layers=num_layers,\n",
    "                    use_cuda=args.cuda,\n",
    "                    batch_size=batch_size,\n",
    "                    dropout_input=dropout_input,\n",
    "                    dropout_hidden=dropout_hidden,\n",
    "                    embedding_dim=embedding_dim, \n",
    "                    shared_embedding=shared_embedding\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall 0.2988362369337979\n",
      "mrr 0.09398002545333074\n"
     ]
    }
   ],
   "source": [
    "save_path = \"../log/samplePaddingSessionRNN/checkpoint/07190203/model_best.pt\"\n",
    "\n",
    "save_model_data = torch.load(save_path)\n",
    "# print(save_model_data)\n",
    "model.load_state_dict(save_model_data['model']) \n",
    "model.eval()\n",
    "recall = save_model_data['recall']\n",
    "print(\"recall\", recall)\n",
    "\n",
    "mrr = save_model_data['mrr']\n",
    "print(\"mrr\", mrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0046,  0.4635,  0.2425,  ..., -0.2431, -0.2885,  0.4390],\n",
       "        [-0.1967,  0.2312, -0.4256,  ...,  0.1649,  0.2620,  0.2347],\n",
       "        [-0.0548, -0.7392,  0.0220,  ..., -0.6229,  0.6161,  0.9687],\n",
       "        ...,\n",
       "        [-0.7595,  0.1734, -0.5826,  ...,  2.1363,  0.0233,  0.0448],\n",
       "        [-0.9475, -0.9853, -0.1102,  ..., -0.1099, -0.3941,  0.4392],\n",
       "        [-0.2130,  0.2578,  0.7439,  ...,  0.8787, -0.5507, -0.4998]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.look_up.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0046,  0.4635,  0.2425,  ..., -0.2431, -0.2885,  0.4390],\n",
       "        [-0.1967,  0.2312, -0.4256,  ...,  0.1649,  0.2620,  0.2347],\n",
       "        [-0.0548, -0.7392,  0.0220,  ..., -0.6229,  0.6161,  0.9687],\n",
       "        ...,\n",
       "        [-0.7595,  0.1734, -0.5826,  ...,  2.1363,  0.0233,  0.0448],\n",
       "        [-0.9475, -0.9853, -0.1102,  ..., -0.1099, -0.3941,  0.4392],\n",
       "        [-0.2130,  0.2578,  0.7439,  ...,  0.8787, -0.5507, -0.4998]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.m_ss.params.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall 0.1413566701497736\n",
      "mrr 0.08586457241696374\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall 0.29677351916376304\n",
      "mrr 0.08824897100078104\n"
     ]
    }
   ],
   "source": [
    "save_path = \"../log/samplePaddingSessionRNN/checkpoint/07181627/model_best.pt\"\n",
    "\n",
    "save_model_data = torch.load(save_path)\n",
    "# print(save_model_data)\n",
    "model.load_state_dict(save_model_data['model']) \n",
    "model.eval()\n",
    "recall = save_model_data['recall']\n",
    "print(\"recall\", recall)\n",
    "\n",
    "mrr = save_model_data['mrr']\n",
    "print(\"mrr\", mrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_type = \"XE\"\n",
    "loss_func = LossFunction(loss_type=loss_type, use_cuda=args.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffling\n",
      "batch num 1435\n",
      "topk 5\n",
      "total_test_num 430500\n",
      "recall 0.12722648083623694\n",
      "mrr 0.07883690043972344\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "dataloader = valid_data_loader\n",
    "\n",
    "losses = []\n",
    "recalls = []\n",
    "mrrs = []\n",
    "weights = []\n",
    "\n",
    "topk = 5\n",
    "eval_iter = 0\n",
    "device = torch.device('cuda')\n",
    "warm_start = args.warm_start\n",
    "with torch.no_grad():\n",
    "    total_test_num = []\n",
    "\n",
    "    for x_batch, y_batch, x_len_batch, idx_batch in dataloader:        \n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        warm_start_mask = (idx_batch>=warm_start)\n",
    "\n",
    "        hidden = model.init_hidden()\n",
    "\n",
    "        output_batch = model(x_batch, hidden, x_len_batch)\n",
    "\n",
    "        # et_1 = datetime.datetime.now()\n",
    "        # print(\"duration 1\", et_1-st)\n",
    "\n",
    "        sampled_logit_batch, sampled_target_batch = model.m_ss(output_batch, y_batch)\n",
    "\n",
    "        loss_batch = loss_func(sampled_logit_batch, sampled_target_batch)\n",
    "        losses.append(loss_batch.item())\n",
    "\n",
    "        # et_2 = datetime.datetime.now()\n",
    "        # print(\"duration 2\", et_2-et_1)\n",
    "\n",
    "        # logit_batch = self.model.m_ss.params(output_batch)\n",
    "        recall_batch, mrr_batch = evaluate(sampled_logit_batch, sampled_target_batch, warm_start_mask, k=topk)\n",
    "\n",
    "        weights.append( int( warm_start_mask.int().sum() ) )\n",
    "        recalls.append(recall_batch)\n",
    "        mrrs.append(mrr_batch)\n",
    "\n",
    "        total_test_num.append(y_batch.view(-1).size(0))\n",
    "\n",
    "mean_losses = np.mean(losses)\n",
    "mean_recall = np.average(recalls, weights=weights)\n",
    "mean_mrr = np.average(mrrs, weights=weights)\n",
    "print(\"topk\", topk)\n",
    "print(\"total_test_num\", np.sum(total_test_num))\n",
    "print(\"recall\", mean_recall)\n",
    "print(\"mrr\", mean_mrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_num 4158\n",
      "zero_cate_num_total 634331\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "dataloader = valid_data_loader\n",
    "\n",
    "losses = []\n",
    "recalls = []\n",
    "mrrs = []\n",
    "weights = []\n",
    "\n",
    "nonzero_cate_num_total = 0\n",
    "\n",
    "topk = 5\n",
    "eval_iter = 0\n",
    "device = torch.device('cuda')\n",
    "warm_start = args.warm_start\n",
    "with torch.no_grad():\n",
    "    total_test_num = []\n",
    "\n",
    "    for x_cate_batch, mask_cate, max_acticonNum_cate, seqLen_cate, x_batch, mask_batch, seqLen_batch, y_batch, idx_batch in dataloader:        \n",
    "        x_cate_batch = x_cate_batch.to(device)\n",
    "        mask_cate = mask_cate.to(device)\n",
    "        \n",
    "        x_batch = x_batch.to(device)\n",
    "        mask_batch = mask_batch.to(device)\n",
    "\n",
    "        y_batch = y_batch.to(device)\n",
    "        warm_start_mask = (idx_batch>=warm_start).to(device)\n",
    "        \n",
    "        nonzero_cate_num = np.count_nonzero(seqLen_cate)\n",
    "        nonzero_cate_num_total += nonzero_cate_num\n",
    "#         print(\"zero_cate_num\", zero_cate_num)\n",
    "#         print(\"seqLen_cate\", seqLen_cate)\n",
    "#         print(seqLen_cate.nonzero())\n",
    "\n",
    "#         exit()\n",
    "print(\"nonzero_cate_num_total\", nonzero_cate_num_total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7627837902837903"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "634331.0/831600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(np.eye(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file name ../Data/tmall/100k_unknown_cate/train/20.pickle\n"
     ]
    }
   ],
   "source": [
    "index = 20\n",
    "folder = \"../Data/tmall/100k_unknown_cate/train\"\n",
    "file_name = folder+\"/\"+str(index)+\".pickle\"\n",
    "print(\"file name\", file_name)\n",
    "f_step = open(file_name, \"rb\")\n",
    "\n",
    "step_data_map = pickle.load(f_step)\n",
    "f_step.close()\n",
    "\n",
    "x_long_cate_action_list_step = step_data_map[\"long_action_cate\"]\n",
    "x_long_cateNum_list_step = step_data_map[\"long_cateNum\"]\n",
    "\n",
    "x_long_cate_actionNum_list_step = step_data_map[\"long_actionNum_cate\"]\n",
    "x_long_cate_list_step = step_data_map[\"long_cate\"]\n",
    "x_short_action_list_step = step_data_map[\"short_action\"]\n",
    "x_short_cate_list_step = step_data_map[\"short_cate\"]\n",
    "x_short_actionNum_list_step = step_data_map[\"short_actionNum\"]\n",
    "y_action_step = step_data_map[\"target_action\"]\n",
    "y_cate_step = step_data_map[\"target_cate\"]\n",
    "y_action_idx_step = step_data_map[\"target_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "456"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_cate_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_cate_step[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn((3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.6493,  0.8490, -0.3502,  1.2809],\n",
      "        [ 0.6891,  0.3602, -1.4018,  0.1154],\n",
      "        [-0.3195,  0.4709, -0.4335,  0.7348]])\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.LongTensor([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n"
     ]
    }
   ],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.LongTensor([[2], [4], [12]])\n",
    "d = b == c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 1]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8490, 0.7348])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[d]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "e = torch.zeros(3)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.sum(dim=1).nonzero().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "e[d.sum(dim=1).nonzero().reshape(-1)] = a[d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8490, 0.0000, 0.7348])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [1, 2]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.8490, -1.4018,  0.7348])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0, 0],\n",
       "        [0, 0, 1, 0],\n",
       "        [0, 0, 0, 1]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[1, 2, 3, 4], [1, 3, 4], [20, 30, 40]]\n",
    "max(max(i) for i in a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  0  1]\n"
     ]
    }
   ],
   "source": [
    "b = a-2\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
