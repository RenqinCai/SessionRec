{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "use time to cut sequences\n",
    "command \n",
    "python main_time.py --data_folder ../Data/xing/ --train_data train_item.pickle --valid_data test_item.pickle --test_data test_item.pickle --data_name xing --embedding_dim 300 --hidden_size 300 --lr 0.005\n",
    "\"\"\"\n",
    "import argparse\n",
    "import torch\n",
    "# import lib\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from loss import *\n",
    "from network import *\n",
    "from optimizer import *\n",
    "from trainer import *\n",
    "from torch.utils import data\n",
    "import pickle\n",
    "import sys\n",
    "from dataset_time import *\n",
    "# from data_time import *\n",
    "from logger import *\n",
    "import collections\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../PyTorch_GBW_LM')\n",
    "sys.path.insert(0, '../PyTorch_GBW_LM/log_uniform')\n",
    "\n",
    "from sampledSoftmax import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--hidden_size', default=50, type=int)\n",
    "parser.add_argument('--num_layers', default=1, type=int)\n",
    "parser.add_argument('--batch_size', default=100, type=int)\n",
    "parser.add_argument('--dropout_input', default=0, type=float)\n",
    "parser.add_argument('--dropout_hidden', default=.2, type=float)\n",
    "\n",
    "# parse the optimizer arguments\n",
    "parser.add_argument('--optimizer_type', default='Adagrad', type=str)\n",
    "parser.add_argument('--final_act', default='tanh', type=str)\n",
    "parser.add_argument('--lr', default=.05, type=float)\n",
    "parser.add_argument('--weight_decay', default=0.0, type=float)\n",
    "parser.add_argument('--momentum', default=0.1, type=float)\n",
    "parser.add_argument('--eps', default=1e-6, type=float)\n",
    "\n",
    "parser.add_argument(\"-seed\", type=int, default=7,\n",
    "                     help=\"Seed for random initialization\")\n",
    "parser.add_argument(\"-sigma\", type=float, default=None,\n",
    "                     help=\"init weight -1: range [-sigma, sigma], -2: range [0, sigma]\")\n",
    "parser.add_argument(\"--embedding_dim\", type=int, default=-1,\n",
    "                     help=\"using embedding\")\n",
    "# parse the loss type\n",
    "parser.add_argument('--loss_type', default='TOP1', type=str)\n",
    "# parser.add_argument('--loss_type', default='BPR', type=str)\n",
    "parser.add_argument('--topk', default=5, type=int)\n",
    "# etc\n",
    "parser.add_argument('--bptt', default=1, type=int)\n",
    "parser.add_argument('--test_observed', default=5, type=int)\n",
    "parser.add_argument('--window_size', default=30, type=int)\n",
    "parser.add_argument('--warm_start', default=5, type=int)\n",
    "\n",
    "parser.add_argument('--n_epochs', default=20, type=int)\n",
    "parser.add_argument('--time_sort', default=False, type=bool)\n",
    "parser.add_argument('--save_dir', default='models', type=str)\n",
    "parser.add_argument('--data_folder', default='../Data/movielen/1m/', type=str)\n",
    "parser.add_argument('--data_action', default='item.pickle', type=str)\n",
    "parser.add_argument('--data_cate', default='cate.pickle', type=str)\n",
    "parser.add_argument('--data_time', default='time.pickle', type=str)\n",
    "parser.add_argument(\"--is_eval\", action='store_true')\n",
    "parser.add_argument('--load_model', default=None,  type=str)\n",
    "parser.add_argument('--checkpoint_dir', type=str, default='checkpoint')\n",
    "parser.add_argument('--data_name', default=None, type=str)\n",
    "parser.add_argument('--shared_embedding', default=None, type=int)\n",
    "parser.add_argument('--patience', default=1000)\n",
    "parser.add_argument('--negative_num', default=1000, type=int)\n",
    "parser.add_argument('--valid_start_time', default=0, type=int)\n",
    "parser.add_argument('--test_start_time', default=0, type=int)\n",
    "parser.add_argument('--model_name', default=\"samplePaddingSessionRNN\", type=str)\n",
    "\n",
    "# Get the arguments\n",
    "args = parser.parse_args([])\n",
    "args.cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA_VISIBLE_DEVICES=0 python eval_main_time.py --data_folder ../Data/tmall/100k_unknown_cate/ \n",
    "# --data_action item_time.pickle --data_cate cate_time.pickle --data_time time_time.pickle \n",
    "# --data_name taobao --embedding_dim 300 --hidden_size 300 --lr 0.001 --window_size 20 \n",
    "# --test_observed 5 --n_epochs 100 --shared_embedding 1 --batch_size 300 \n",
    "# --optimizer_type Adam --loss_type 'XE' --valid_start_time 1512172800 --test_start_time 1512259200 \n",
    "# --negative_num 10000 --topk 20 --checkpoint_dir \"../log/samplePaddingSessionRNN/checkpoint/01022149\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.data_folder = \"../../../Data/tmall/100k_unknown_cate/\"\n",
    "args.data_action = \"item_time.pickle\"\n",
    "args.data_cate = \"cate_time.pickle\"\n",
    "args.data_time = \"time_time.pickle\"\n",
    "args.data_name = \"taobao\"\n",
    "args.embedding_dim = 256\n",
    "args.hidden_size = 256\n",
    "args.lr = 0.001\n",
    "args.window_size = 20\n",
    "args.test_observed = 5\n",
    "args.n_epochs = 100\n",
    "args.shared_embedding = 1\n",
    "args.batch_size = 8\n",
    "args.optimizer_type = \"Adam\"\n",
    "args.loss_type = \"XE\"\n",
    "args.valid_start_time = 1512172800\n",
    "args.test_start_time = 1512259200\n",
    "args.negative_num = 10000\n",
    "args.topk = 20\n",
    "args.checkpoint_dir = \"../../log/samplePaddingSessionRNN/checkpoint/01031151\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(7)\n",
    "random.seed(args.seed)\n",
    "\n",
    "if args.cuda:\n",
    "    print(\"gpu\")\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "else:\n",
    "    print(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1512172800: 12/02/2017 @ 12:00am (UTC)\n",
    "### 1512187200: 12/02/2017 @ 4:00am (UTC)\n",
    "## 1512201600: 12/02/2017 @ 8:00am (UTC)\n",
    "### 1512216000: 12/02/2017 @ 12:00pm (UTC)\n",
    "### 1512230400: 12/02/2017 @ 4:00pm (UTC)\n",
    "### 1512244800: 12/02/2017 @ 8:00pm (UTC)\n",
    "# 1512259200: 12/03/2017 @ 12:00am (UTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_checkpoint_dir(log):\n",
    "    print(\"PARAMETER\" + \"-\"*10)\n",
    "    now = datetime.datetime.now()\n",
    "    S = '{:02d}{:02d}{:02d}{:02d}'.format(now.month, now.day, now.hour, now.minute)\n",
    "    checkpoint_dir = \"../log/\"+args.model_name+\"/\"+args.checkpoint_dir\n",
    "    args.checkpoint_dir = checkpoint_dir\n",
    "    save_dir = os.path.join(args.checkpoint_dir, S)\n",
    "\n",
    "    if not os.path.exists(\"../log\"):\n",
    "        os.mkdir(\"../log\")\n",
    "    \n",
    "    if not os.path.exists(\"../log/\"+args.model_name):\n",
    "        os.mkdir(\"../log/\"+args.model_name)\n",
    "\n",
    "    if not os.path.exists(args.checkpoint_dir):\n",
    "        os.mkdir(args.checkpoint_dir)\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "\n",
    "    args.checkpoint_dir = save_dir\n",
    "    \n",
    "    with open(os.path.join(args.checkpoint_dir, 'parameter.txt'), 'w') as f:\n",
    "        for attr, value in sorted(args.__dict__.items()):\n",
    "            msg = \"{}={}\".format(attr.upper(), value)\n",
    "            log.addOutput2IO(msg)\n",
    "            f.write(\"{}={}\\n\".format(attr.upper(), value))\n",
    "\n",
    "    msg = \"---------\" + \"-\"*10\n",
    "    log.addOutput2IO(msg)\n",
    "\n",
    "def load_args(model_path):\n",
    "    model_file = os.path.join(model_path, \"model_best.pt\")\n",
    "    print(\"args file load\", model_file)\n",
    "    check_point = torch.load(model_file)\n",
    "    args = check_point['args']\n",
    "\n",
    "def load_model(network, model_path):\n",
    "    print(\"reload model\")\n",
    "    model_file = os.path.join(model_path, \"model_best.pt\")\n",
    "    print(\"model file\", model_file)\n",
    "    check_point = torch.load(model_file)\n",
    "\n",
    "    network.load_state_dict(check_point['model'])\n",
    "\n",
    "def count_parameters(model):\n",
    "    parameter_num = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(\"parameter_num\", parameter_num) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args file load ../../log/samplePaddingSessionRNN/checkpoint/01031151/model_best.pt\n",
      "device cuda\n",
      "**********train load**********\n",
      "action seq num 51275\n",
      "time seq num 51275\n",
      "loading item map\n",
      "loading item map\n",
      "observed_threshold 5 20\n",
      "loading data\n",
      "valid_start_time 1512172800\n",
      "test start time 1512259200\n",
      "seq num for training 2738883\n",
      "seq num of actions for training 2738883\n",
      "seq num for testing 430797\n",
      "seq num of actions for testing 430797\n",
      "load data duration  0:00:12.434604\n",
      "++++++++++valid load++++++++++\n",
      "item num 68008\n",
      "seq num 2738883\n",
      "batch size 8\n",
      "batch_num 342360\n",
      "seq num 430797\n",
      "batch size 8\n",
      "batch_num 53849\n",
      "seq num 430797\n",
      "batch size 8\n",
      "batch_num 53849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/sr3hd/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reload model\n",
      "model file ../../log/samplePaddingSessionRNN/checkpoint/01031151/model_best.pt\n"
     ]
    }
   ],
   "source": [
    "model_path = args.checkpoint_dir\n",
    "load_args(model_path)\n",
    "\n",
    "BPTT = args.bptt\n",
    "\n",
    "device = torch.device('cuda' if args.cuda else 'cpu')\n",
    "print(\"device\", device)\n",
    "\n",
    "if args.embedding_dim == -1:\n",
    "    raise AssertionError()\n",
    "\n",
    "data_name = args.data_name\n",
    "\n",
    "print(\"*\"*10+\"train load\"+\"*\"*10)\n",
    "\n",
    "observed_threshold = args.test_observed\n",
    "\n",
    "data_action = args.data_folder+args.data_action\n",
    "data_cate = args.data_folder+args.data_cate\n",
    "data_time = args.data_folder+args.data_time\n",
    "\n",
    "valid_start_time = args.valid_start_time\n",
    "test_start_time = args.test_start_time\n",
    "\n",
    "st = datetime.datetime.now()\n",
    "data_obj = MYDATA(data_action, data_cate, data_time, valid_start_time, test_start_time, observed_threshold, args.window_size)\n",
    "et = datetime.datetime.now()\n",
    "print(\"load data duration \", et-st)\n",
    "\n",
    "train_data = data_obj.train_dataset\n",
    "valid_data = data_obj.test_dataset\n",
    "test_data = data_obj.test_dataset\n",
    "\n",
    "print(\"+\"*10+\"valid load\"+\"+\"*10)\n",
    "\n",
    "input_size = data_obj.items()\n",
    "output_size = input_size\n",
    "\n",
    "negative_num = args.negative_num\n",
    "\n",
    "train_data_loader = MYDATALOADER(train_data, args.batch_size)\n",
    "valid_data_loader = MYDATALOADER(valid_data, args.batch_size)\n",
    "test_data_loader = MYDATALOADER(valid_data, args.batch_size)\n",
    "\n",
    "ss = SampledSoftmax(output_size, negative_num, args.embedding_dim, None)\n",
    "\n",
    "network = NETWORK(input_size, ss, args, device)\n",
    "load_model(network, model_path)\n",
    "\n",
    "### eval\n",
    "loss_function = LossFunction(device, loss_type=args.loss_type)\n",
    "\n",
    "topk = args.topk\n",
    "eval = Evaluation(None, network, loss_function, device, topk, args.warm_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_item_freq_dict = dict(Counter(train_data.m_y_action))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model Output to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([68008]) cuda:0\n"
     ]
    }
   ],
   "source": [
    "train_item_freq_list = [train_item_freq_dict[i] if i in train_item_freq_dict else 0.0 for i in range(input_size)]\n",
    "item_pop = torch.from_numpy(np.array(train_item_freq_list)).to(device)\n",
    "item_pop = item_pop+1e-20\n",
    "print(item_pop.size(), item_pop.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compensation(logits, beta):\n",
    "    logits = logits*beta+(1-beta)\n",
    "    \n",
    "#     print(\"logits\", logits, torch.max(logits, dim=-1))\n",
    "    com_logits = logits/item_pop.unsqueeze(0)\n",
    "#     print(\"com_logits 1\", com_logits, torch.max(com_logits, dim=-1))\n",
    "    return com_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compensated_score(logits, alpha, beta):\n",
    "    com_logits = compensation(logits, beta)\n",
    "    \n",
    "    com_logits[:, 0] = 0\n",
    "    com_logits[:, 67420] = 0\n",
    "        \n",
    "    n_u = torch.norm(logits, dim=-1, keepdim=True)\n",
    "    m_u = torch.norm(com_logits, dim=-1, keepdim=True)\n",
    "    \n",
    "#     print(\"n_u\", n_u.size())\n",
    "#     print(\"m_u\", m_u.size())\n",
    "    tmp = alpha*com_logits*n_u/m_u\n",
    "    final_score = logits+tmp\n",
    "#     print(\"tmp\", tmp)\n",
    "#     print(\"n_u\", n_u)\n",
    "#     print(\"m_u\", m_u)\n",
    "#     print(\"logits\", logits)\n",
    "    \n",
    "    return final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_to_file(eval_data, file_name, alpha=0.6, beta=0.8):\n",
    "    network.eval()\n",
    "    \n",
    "    dataloader = eval_data\n",
    "    topk = 20\n",
    "    header = False\n",
    "    cols = [\"user\"] + list(range(topk)) + [\"target\"]\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for x_short_action_batch, mask_short_action_batch, \\\n",
    "            pad_x_short_actionNum_batch, y_action_batch, y_action_idx_batch, user_batch in dataloader:\n",
    "        \n",
    "                \n",
    "            x_short_action_batch = x_short_action_batch.to(device)\n",
    "            mask_short_action_batch = mask_short_action_batch.to(device)\n",
    "            y_action_batch = y_action_batch.to(device)\n",
    "            user_batch = user_batch.to(device)\n",
    "\n",
    "            output_batch = network(x_short_action_batch, mask_short_action_batch, pad_x_short_actionNum_batch)\n",
    "\n",
    "            sampled_logit_batch, sampled_target_batch = network.m_ss(output_batch, y_action_batch, \\\n",
    "                                                        None, None, None, None, None, None, \"full\")\n",
    "\n",
    "            compensated_logits = compensated_score(sampled_logit_batch, alpha, beta)\n",
    "\n",
    "            _, preds = torch.topk(compensated_logits, topk, -1)\n",
    "            preds = preds.cpu()\n",
    "            targets = sampled_target_batch.cpu()\n",
    "            \n",
    "            model_dfs = []\n",
    "            # Store each sequence's user, predictions in topk, and target\n",
    "            # Can change the above to store all logits, but is very slow\n",
    "            for i in range(len(user_batch)):\n",
    "                data = [[user_batch[i].item()] + preds[i].tolist() + [targets[i].item()]]\n",
    "                df = pd.DataFrame(data, columns=cols)\n",
    "                model_dfs.append(df)\n",
    "                \n",
    "            df = pd.concat(model_dfs, ignore_index=True)\n",
    "            if not header:\n",
    "                df.to_csv(file_name+\".csv.gz\", mode='a', index=False, compression=\"gzip\")\n",
    "                header = True\n",
    "            else:\n",
    "                df.to_csv(file_name+\".csv.gz\", mode='a', index=False, header=False, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_file(train_data_loader, \"train_logits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffling\n"
     ]
    }
   ],
   "source": [
    "model_to_file(test_data_loader, \"compensated_test@20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = pd.read_csv(\"test_results.csv.gz\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>67997</th>\n",
       "      <th>67998</th>\n",
       "      <th>67999</th>\n",
       "      <th>68000</th>\n",
       "      <th>68001</th>\n",
       "      <th>68002</th>\n",
       "      <th>68003</th>\n",
       "      <th>68004</th>\n",
       "      <th>68005</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1512214656</td>\n",
       "      <td>21345</td>\n",
       "      <td>2296</td>\n",
       "      <td>2215</td>\n",
       "      <td>665</td>\n",
       "      <td>2839</td>\n",
       "      <td>1943</td>\n",
       "      <td>984</td>\n",
       "      <td>932</td>\n",
       "      <td>3738</td>\n",
       "      <td>...</td>\n",
       "      <td>39043</td>\n",
       "      <td>54799</td>\n",
       "      <td>51280</td>\n",
       "      <td>53946</td>\n",
       "      <td>30428</td>\n",
       "      <td>67985</td>\n",
       "      <td>54818</td>\n",
       "      <td>56529</td>\n",
       "      <td>44547</td>\n",
       "      <td>6344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1512227492</td>\n",
       "      <td>2</td>\n",
       "      <td>455</td>\n",
       "      <td>110</td>\n",
       "      <td>441</td>\n",
       "      <td>10917</td>\n",
       "      <td>803</td>\n",
       "      <td>41175</td>\n",
       "      <td>90</td>\n",
       "      <td>2364</td>\n",
       "      <td>...</td>\n",
       "      <td>53016</td>\n",
       "      <td>51188</td>\n",
       "      <td>67352</td>\n",
       "      <td>63964</td>\n",
       "      <td>54900</td>\n",
       "      <td>56624</td>\n",
       "      <td>63482</td>\n",
       "      <td>65649</td>\n",
       "      <td>58592</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1512223187</td>\n",
       "      <td>5696</td>\n",
       "      <td>9102</td>\n",
       "      <td>2761</td>\n",
       "      <td>11937</td>\n",
       "      <td>3877</td>\n",
       "      <td>2408</td>\n",
       "      <td>331</td>\n",
       "      <td>7374</td>\n",
       "      <td>13034</td>\n",
       "      <td>...</td>\n",
       "      <td>67927</td>\n",
       "      <td>65108</td>\n",
       "      <td>62481</td>\n",
       "      <td>15638</td>\n",
       "      <td>65871</td>\n",
       "      <td>56429</td>\n",
       "      <td>32500</td>\n",
       "      <td>67420</td>\n",
       "      <td>66440</td>\n",
       "      <td>6722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 68008 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user      0     1     2      3      4     5      6     7      8  ...  \\\n",
       "0  1512214656  21345  2296  2215    665   2839  1943    984   932   3738  ...   \n",
       "1  1512227492      2   455   110    441  10917   803  41175    90   2364  ...   \n",
       "2  1512223187   5696  9102  2761  11937   3877  2408    331  7374  13034  ...   \n",
       "\n",
       "   67997  67998  67999  68000  68001  68002  68003  68004  68005  target  \n",
       "0  39043  54799  51280  53946  30428  67985  54818  56529  44547    6344  \n",
       "1  53016  51188  67352  63964  54900  56624  63482  65649  58592     444  \n",
       "2  67927  65108  62481  15638  65871  56429  32500  67420  66440    6722  \n",
       "\n",
       "[3 rows x 68008 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df.head(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
